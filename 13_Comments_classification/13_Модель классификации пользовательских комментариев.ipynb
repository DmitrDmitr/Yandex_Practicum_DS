{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОПИСАНИЕ ПРОЕКТА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, вернее клиенты предлагают свои правки и комментируют изменения других. Необходим инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Задача - обучить модель классифицировать комментарии на позитивные и негативные. В наличии - набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Метрика качества *F1* должна быть не меньше 0.75. \n",
    "\n",
    "### Инструкция по выполнению проекта\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библитеки и методы\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import nltk\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "from tqdm import notebook\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем исходный файл\n",
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESCRIBE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.101679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159571.000000\n",
       "mean        0.101679\n",
       "std         0.302226\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPACES\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUPLICATES\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Смотрим общую информацию\n",
    "print('INFO')\n",
    "display(data.info())\n",
    "print('HEAD 10')\n",
    "display(data.head(10))\n",
    "print('DESCRIBE')\n",
    "display(data.describe())\n",
    "print('SPACES')\n",
    "display(data.isnull().sum())\n",
    "print('DUPLICATES')\n",
    "display(data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо привести все записи к одному регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учитывая, что абсолютное большинство записей на английском языке - проведем лемматизацию с помощью `WordNetLemmatizer`, а также очистим тексты от лишних символов, с помощью регулярных выражений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество текстов: 159571\n",
      "Проверка лемматизации\n",
      " Исходный текст data[1]: d aww he match this background colour i m seemingly stuck with thanks talk january utc\n",
      "Лемматизированный текст data[1]: d aww he match this background colour i m seemingly stuck with thanks talk january utc\n",
      "CPU times: user 2min 1s, sys: 436 ms, total: 2min 1s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "corpus = list(data['text'])\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Создаем функцию лемматизации\n",
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lemm_text = ' '.join([lemmatizer.lemmatize(w) for w in word_list])   \n",
    "    return lemm_text\n",
    "\n",
    "# Создаем функцию чистки\n",
    "def clear_text(text):\n",
    "    return   \" \".join(re.sub(r'[^a-zA-Z ]', ' ', text).split())\n",
    "\n",
    "print(\"Количество текстов:\", len(data['text']))\n",
    "print('Проверка лемматизации')\n",
    "print(\" Исходный текст data[1]:\", data['text'][1])\n",
    "for i in range(len(data['text'])):\n",
    "    data.loc[i,'text']= lemmatize(clear_text(corpus[i]))\n",
    "    print(\"Прогресс, %:\", i/159571*100)\n",
    "print(\"Лемматизированный текст data[1]:\", data['text'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Контрольная проверка на пропуски и дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPACES\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUPLICATES\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('SPACES')\n",
    "display(data.isnull().sum())\n",
    "print('DUPLICATES')\n",
    "display(data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдается незначительное, относительно общего размера выборки, количество дубликатов. Удалим их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим обучающую, вадидационную и тестовую выборки последовательным разбиением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = train_test_split(data, test_size = 0.4, random_state = 12345)\n",
    "data_valid, data_test = train_test_split(data_valid, test_size = 0.5, random_state = 12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим размерность выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: (95710, 2)\n",
      "Валидная выборка: (31904, 2)\n",
      "Тестовая выборка: (31904, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Обучающая выборка:\", data_train.shape)\n",
    "print(\"Валидная выборка:\", data_valid.shape)\n",
    "print(\"Тестовая выборка:\", data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим переменные для признаков и целевого признака, для каждой из выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = data_train.drop(['toxic'], axis=1)\n",
    "target_train = data_train['toxic']\n",
    "features_valid = data_valid.drop(['toxic'], axis=1)\n",
    "target_valid = data_valid['toxic']\n",
    "features_test = data_test.drop(['toxic'], axis=1)\n",
    "target_test = data_test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим матрицы cо значениями TF-IDF по корпусу сообщений. Укажем стоп-слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words = stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выборка features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (95710, 138499)\n"
     ]
    }
   ],
   "source": [
    "corpus_train = list(features_train['text'])\n",
    "tf_idf_train = count_tf_idf.fit_transform(corpus_train)\n",
    "\n",
    "print(\"Размер матрицы:\", tf_idf_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выборка features_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (31904, 138499)\n"
     ]
    }
   ],
   "source": [
    "corpus_valid = list(features_valid['text'])\n",
    "tf_idf_valid = count_tf_idf.transform(corpus_valid)\n",
    "\n",
    "print(\"Размер матрицы:\", tf_idf_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выборка features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (31904, 138499)\n"
     ]
    }
   ],
   "source": [
    "corpus_test = list(features_test['text'])\n",
    "tf_idf_test = count_tf_idf.transform(corpus_test)\n",
    "\n",
    "print(\"Размер матрицы:\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка. Выводы.\n",
    "\n",
    "- исходный датасет состоит 159571 записей с 2 признаками\n",
    "- названия столбцов информативны и удобочитаемы\n",
    "- типы данных признаков подходят для дальнейших расчетов\n",
    "- все значения признака `text` были приведены к нижнему регистру\n",
    "- в исходном датасете пробелы и дубликаты не обнаружены\n",
    "- произведена лемматизация текстов. Учитывая, что все тексты признака `text` на английском языке - для лемматизации применен `WordNetLemmatizer`\n",
    "- тексты очищены от лишних символов, с помощью регулярных выражений\n",
    "- после лемматизации обнаружено незначительное количество дубликатов, которые были удалены\n",
    "- последовательным разбиением исходного датасета созданы: обучающая (60% записей), валидационная и тестовая выборки (по 20% записей соответственно)\n",
    "- созданы переменные для признаков и целевого признака каждой из выборок\n",
    "- созданы матрицы со значениями `TF-IDF` и отдельные переменные для признаков каждой выборки\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Модель DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем оптимальные гиперпараметры с помощью `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTC_gridsearchcv(features, target):\n",
    "    model = DecisionTreeClassifier()\n",
    "    param_grid = { \n",
    "        'random_state': [12345],\n",
    "        'max_depth': np.arange(10, 51, 10),\n",
    "        'class_weight' : ['balanced']\n",
    "    }\n",
    "    CV = GridSearchCV(estimator = model, param_grid = param_grid, cv = 3, scoring = 'f1')\n",
    "    CV.fit(features, target)\n",
    "    print('Лучшие гиперпараметры: ', CV.best_params_)\n",
    "    print('Лучшая F1-мера: {:.2f}'.format(CV.best_score_))\n",
    "    return CV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оптимальные параметры по TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры:  {'class_weight': 'balanced', 'max_depth': 50, 'random_state': 12345}\n",
      "Лучшая F1-мера: 0.62\n",
      "CPU times: user 5min 39s, sys: 740 ms, total: 5min 40s\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_params_DTC_tfidf = DTC_gridsearchcv(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели, с оптимальными гиперпараметрами, на тренинговой выборке и оценка на валидной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(model, features_train, target_train, features_valid, target_valid):\n",
    "    '''\n",
    "    Функция принимает в качестве аргументов: модель, признаки и целевой признак выборки для обучения и тестирования.\n",
    "    Функция обучает заданную модель по обучающей выборке и расчитывает метрики по валидационной выборке: accuracy, F1-меру.\n",
    "    '''\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, predictions)\n",
    "    print('Точность модели:{:.2%}'. format(accuracy))\n",
    "    print('F1-мера: {:.2f}'. format(f1_score(target_valid, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели:91.73%\n",
      "F1-мера: 0.62\n",
      "CPU times: user 41.2 s, sys: 55.7 ms, total: 41.3 s\n",
      "Wall time: 41.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_DTC_tfidf = DecisionTreeClassifier(class_weight = 'balanced', max_depth = 50, random_state = 12345)\n",
    "learning(model_DTC_tfidf, tf_idf_train, target_train, tf_idf_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Модель LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем оптимальные гиперпараметры с помощью GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_gridsearchcv(features, target):\n",
    "    model = LogisticRegression()\n",
    "    param_grid = { \n",
    "        'random_state': [12345],\n",
    "        'solver': ['liblinear'],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'class_weight' : ['balanced']\n",
    "    }\n",
    "    CV = GridSearchCV(estimator = model, param_grid = param_grid, cv= 3, scoring = 'f1')\n",
    "    CV.fit(features, target)\n",
    "    print('Лучшие гиперпараметры: ', CV.best_params_)\n",
    "    print('Лучшая F1-мера: {:.2f}'.format(CV.best_score_))\n",
    "    return CV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оптимальные параметры по TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры:  {'class_weight': 'balanced', 'penalty': 'l1', 'random_state': 12345, 'solver': 'liblinear'}\n",
      "Лучшая F1-мера: 0.76\n",
      "CPU times: user 14 s, sys: 139 ms, total: 14.2 s\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_params_LR_tfidf = LR_gridsearchcv(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели, с оптимальными гиперпараметрами, на тренинговой выборке и оценка на валидной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели:94.23%\n",
      "F1-мера: 0.75\n",
      "CPU times: user 1.98 s, sys: 0 ns, total: 1.98 s\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_LR_tfidf = LogisticRegression(class_weight  = 'balanced', penalty = 'l1', random_state = 12345, solver = 'liblinear')\n",
    "learning(model_LR_tfidf, tf_idf_train, target_train, tf_idf_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Модель RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем оптимальные гиперпараметры с помощью GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFC_gridsearchcv(features, target):\n",
    "    model = RandomForestClassifier()\n",
    "    param_grid = { \n",
    "        'random_state': [12345],\n",
    "        'max_depth': np.arange(10, 51, 10),\n",
    "        'n_estimators' : np.arange(10, 51, 10),\n",
    "        'class_weight' : ['balanced']\n",
    "    }\n",
    "    CV = GridSearchCV(estimator = model, param_grid = param_grid, cv= 3, scoring = 'f1')\n",
    "    CV.fit(features, target)\n",
    "    print('Лучшие гиперпараметры: ', CV.best_params_)\n",
    "    print('Лучшая F1-мера: {:.2f}'.format(CV.best_score_))\n",
    "    return CV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оптимальные параметры по TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры:  {'class_weight': 'balanced', 'max_depth': 50, 'n_estimators': 50, 'random_state': 12345}\n",
      "Лучшая F1-мера: 0.48\n",
      "CPU times: user 14min 8s, sys: 4.73 s, total: 14min 12s\n",
      "Wall time: 14min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_params_RFC_tfidf = RFC_gridsearchcv(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели, с оптимальными гиперпараметрами, на тренинговой выборке и оценка на валидной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели:82.41%\n",
      "F1-мера: 0.47\n",
      "CPU times: user 16.4 s, sys: 77.3 ms, total: 16.5 s\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_RFC_tfidf = RandomForestClassifier(class_weight  = 'balanced', random_state = 12345, max_depth = 50, n_estimators = 50)\n",
    "learning(model_RFC_tfidf, tf_idf_train, target_train, tf_idf_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, при использованиии TF-IDF, наилучшие результаты показывает модель LogisticRegression (accuracy = 94.17%, f1 = 0.75). Проведем ее финальное тестирование на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели:94.18%\n",
      "f1_score_test = 0.75\n",
      "CPU times: user 13 ms, sys: 1.42 ms, total: 14.4 ms\n",
      "Wall time: 12.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions_LR_test = model_LR_tfidf.predict(tf_idf_test)\n",
    "accuracy = accuracy_score(target_test, predictions_LR_test)\n",
    "print('Точность модели:{:.2%}'. format(accuracy))\n",
    "print(\"f1_score_test = {:.2f}\".format(f1_score(target_test, predictions_LR_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Успешно. Достигнут необходимый уровень меры F1 = 0,75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение. Выводы.\n",
    "\n",
    "- проведено обучение тремя алгоритмами: DecisionTreeClassifier, LogisticRegression, RandomForestClassifier\n",
    "- для борьбы с дисбалансом классов был применен гиперпараметр \"balanced\"\n",
    "- c помощью `GridSearchCV` проведен подбор оптимальных гиперпараметров:\n",
    "    - `DecisionTreeClassifier` (class_weight = 'balanced', max_depth = 50, random_state = 12345)\n",
    "    - `LogisticRegression` (class_weight  = 'balanced', penalty = 'l1', random_state = 12345, solver = 'liblinear')\n",
    "    - `RandomForestClassifier` (class_weight  = 'balanced', random_state = 12345, max_depth = 50, n_estimators = 50)\n",
    "- по результатам обучения получены следующие результаты:\n",
    "    - `DecisionTreeClassifier` (F1 = 0,66)\n",
    "    - `LogisticRegression` (F1 = 0,75)\n",
    "    - `RandomForestClassifier` (F1 = 0,47)\n",
    "- на этапе обучения лучший результат продемонстрирован алгоритмом `LogisticRegression` (F1 = 0,75)\n",
    "- на этапе финального тестирования, на тестовой выборке, алгоритм `LogisticRegression` подтвердил свою эффективность, показав необходимый, по условиям проекта, уровень меры F1 = 0,75 и accuracy = 94,18%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. BERT\n",
    "\n",
    "Принимая во внимание, что BERT очень требователен к ресурсам и как следствие времязатратен - в данном разделе мы только ознакомимся с принципом его работы, не претендуя, по результатам, на получение сколь-либо значимой меры F1, так как в задачах работы с текстом и изображениями ключевую роль играет объем выборки.\n",
    "За неимением достаточных ресурсов, в виде GPU, продемонстрируем работу BERT на малой выборке - 10 000 записей из исходного датасета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем исходный файл\n",
    "data = pd.read_csv('/Users/Anonim/Downloads/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Смотрим размерность\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем выборку из 10 000 записей\n",
    "data = data.sample(10000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPACES\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUPLICATES\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Проверяем на пропуски и дубликаты\n",
    "print('SPACES')\n",
    "display(data.isnull().sum())\n",
    "print('DUPLICATES')\n",
    "display(data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем предобученную модель и токенизатор BERT (мультиязычную версию)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_bert = transformers.BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проводим токенизацию (преобразуем каждое предложение в список идентификаторов, максимальная длина = 512, но для экономии времени обучения ограничимся длиной = 8). Берем предложения очищенные от символов. Лемматизация не требуется, так как BERT понимает формы слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 946 ms, sys: 2.29 ms, total: 949 ms\n",
      "Wall time: 947 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add_special_token добавляет токены в начале и конце каждого предложения\n",
    "tokenized = data['text'].apply((lambda x: tokenizer.encode(x[:8], add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В связи с требованиями к работе модели BERT - приводим все векторы к одной длине"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создаем счетчик для определения максимальной длины вектора\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "        \n",
    "# приводим полученные векторы к максимальному размеру за счет прибавления\n",
    "# к более коротким векторам идентификатора 0 (padding)\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указываем модели, что нули в векторах не несут значимой информации. Это необходимо для компоненты модели - attention. Отбросим эти токены и создадим \"маску\" для действительно важных токенов - укажем нулевые и не нулевые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем обученный BERT для создания эмбеддингов для каждого текста по 100 текстов в батче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45917329b33449698cc4287367a8848a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model_bert(batch, attention_mask=attention_mask_batch) \n",
    "        \n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяем эмбеддинги для каждого текста, которые получились по результатам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_bert = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем данные на обучающую и тестовую выборки и создаем переменные для признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bert = data['toxic'].iloc[0:10000]\n",
    "features_bert_train, features_bert_test, target_bert_train, target_bert_test = train_test_split(features_bert, target_bert, test_size = 0.25, random_state = 12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Модель DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем оптимальные гиперпараметры с помощью `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оптимальные параметры по BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры:  {'class_weight': 'balanced', 'max_depth': 20, 'random_state': 12345}\n",
      "Лучшая F1-мера: 0.25\n",
      "CPU times: user 48.7 s, sys: 84.8 ms, total: 48.8 s\n",
      "Wall time: 48.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_params_DTC_bert = DTC_gridsearchcv(features_bert_train, target_bert_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели, с оптимальными гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели:52.16%\n",
      "F1-мера: 0.24\n",
      "CPU times: user 560 ms, sys: 1.97 ms, total: 562 ms\n",
      "Wall time: 561 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_DTC_bert = DecisionTreeClassifier(class_weight = 'balanced', max_depth = 1, random_state = 12345)\n",
    "learning(model_DTC_bert, features_bert_train, target_bert_train, features_bert_test, target_bert_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем оптимальные гиперпараметры с помощью `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оптимальные параметры по BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры:  {'class_weight': 'balanced', 'penalty': 'l2', 'random_state': 12345, 'solver': 'liblinear'}\n",
      "Лучшая F1-мера: 0.26\n",
      "CPU times: user 8min 46s, sys: 752 ms, total: 8min 47s\n",
      "Wall time: 8min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_params_LR_bert = LR_gridsearchcv(features_bert_train, target_bert_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели, с оптимальными гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели:52.16%\n",
      "F1-мера: 0.24\n",
      "CPU times: user 582 ms, sys: 3.98 ms, total: 586 ms\n",
      "Wall time: 589 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_LR_bert = LogisticRegression(class_weight = 'balanced', penalty = 'l2', random_state = 12345, solver = 'liblinear')\n",
    "learning(model_DTC_bert, features_bert_train, target_bert_train, features_bert_test, target_bert_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем оптимальные гиперпараметры с помощью `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оптимальные параметры по BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры:  {'class_weight': 'balanced', 'max_depth': 10, 'n_estimators': 40, 'random_state': 12345}\n",
      "Лучшая F1-мера: 0.25\n",
      "CPU times: user 2min 32s, sys: 825 ms, total: 2min 33s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_params_RFC_bert = RFC_gridsearchcv(features_bert_train, target_bert_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели, с оптимальными гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели:52.16%\n",
      "F1-мера: 0.24\n",
      "CPU times: user 578 ms, sys: 2.18 ms, total: 580 ms\n",
      "Wall time: 578 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_RFC_bert = RandomForestClassifier(class_weight = 'balanced', max_depth = 10, n_estimators = 40, random_state = 12345)\n",
    "learning(model_DTC_bert, features_bert_train, target_bert_train, features_bert_test, target_bert_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. BERT. Выводы.\n",
    "\n",
    "К сожалению, в связи с ресурсными ограничениями, с объемом выборки в 10 000 записей не удалось достичь уровня F1 = 0,75\n",
    "\n",
    "Как результат:\n",
    "\n",
    "- на практике ознакомились с работой BERT\n",
    "- BERT очень требователен к ресурсам\n",
    "- BERT не требует предварительной лемматизации\n",
    "- ключевое значение для эффективной работы алгоритма имеет объем выборки (чем больше, тем лучше)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Общий вывод\n",
    "\n",
    "#### Цели проекта\n",
    "\n",
    "Для исследования был представлен набор данных с разметкой о токсичности правок. Необходимо обучить модель классифицировать комментарии на позитивные и негативные, со значением метрики качества F1 не меньше 0.75.\n",
    "\n",
    "#### Общая информация о данных\n",
    "\n",
    "- исходный датасет состоит 159571 записей с 2 признаками\n",
    "- названия столбцов информативны и удобочитаемы\n",
    "- типы данных признаков подходят для дальнейших расчетов\n",
    "- все значения признака `text` были приведены к нижнему регистру\n",
    "- в исходном датасете пробелы и дубликаты не обнаружены\n",
    "- произведена лемматизация текстов. Учитывая, что все тексты признака `text` на английском языке - для лемматизации применен `WordNetLemmatizer`\n",
    "- тексты очищены от лишних символов, с помощью регулярных выражений\n",
    "- после лемматизации обнаружено незначительное количество дубликатов, которые были удалены\n",
    "- последовательным разбиением исходного датасета созданы: обучающая (60% записей), валидационная и тестовая выборки (по 20% записей соответственно)\n",
    "- созданы переменные для признаков и целевого признака каждой из выборок\n",
    "- созданы матрицы со значениями `TF-IDF` и отдельные переменные для признаков каждой выборки\n",
    "\n",
    "#### Результаты исследования различных моделей\n",
    "\n",
    "- проведено обучение тремя алгоритмами: DecisionTreeClassifier, LogisticRegression, RandomForestClassifier\n",
    "- для борьбы с дисбалансом классов был применен гиперпараметр \"balanced\"\n",
    "- c помощью `GridSearchCV` проведен подбор оптимальных гиперпараметров:\n",
    "    - `DecisionTreeClassifier` (class_weight = 'balanced', max_depth = 50, random_state = 12345)\n",
    "    - `LogisticRegression` (class_weight  = 'balanced', penalty = 'l1', random_state = 12345, solver = 'liblinear')\n",
    "    - `RandomForestClassifier` (class_weight  = 'balanced', random_state = 12345, max_depth = 50, n_estimators = 50)\n",
    "- по результатам обучения получены следующие результаты:\n",
    "    - `DecisionTreeClassifier` (F1 = 0,66)\n",
    "    - `LogisticRegression` (F1 = 0,75)\n",
    "    - `RandomForestClassifier` (F1 = 0,47)\n",
    "- на этапе обучения лучший результат продемонстрирован алгоритмом `LogisticRegression` (F1 = 0,75)\n",
    "- на этапе финального тестирования, на тестовой выборке, алгоритм `LogisticRegression` подтвердил свою эффективность, показав необходимый, по условиям проекта, уровень меры F1 = 0,75 и accuracy = 94,17%\n",
    "\n",
    "Также, в ознакомительных целях, было осуществлено обучение тех же моделей, но с использованием метода BERT. В связи с ресурсными ограничениями, с объемом выборки в 10 000 записей не удалось достичь уровня F1 = 0,75.\n",
    "\n",
    "===================================================================================================================\n",
    "#### Благодарю за внимание."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
